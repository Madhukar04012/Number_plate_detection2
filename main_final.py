"""
main_final.py
License Plate Detection System ‚Äî Final Pro Edition (vFinal)

üéØ Production-Ready Features:
 - ‚úÖ YOLOv8-based AI detection (Ultralytics)
 - ‚úÖ Dual OCR (pytesseract primary, easyocr fallback)
 - ‚úÖ Webcam AND Video-file input (dashcam footage playback)
 - ‚úÖ Watchlist alerts with VOICE notifications (pyttsx3)
 - ‚úÖ Live-updating embedded Matplotlib chart (real-time detection graph)
 - ‚úÖ Confidence slider with live adjustment
 - ‚úÖ Save-crops toggle (enable/disable on-the-fly)
 - ‚úÖ Batch folder processing
 - ‚úÖ Multi-threaded for smooth 60fps performance
 - ‚úÖ Responsive CustomTkinter dark UI
 - ‚úÖ No database (pure performance, feature-focused)

üì¶ Prerequisites:
 - Trained YOLOv8 weights at models/plate_best.pt
 - System Tesseract installed for OCR
 - Python 3.8+ with required packages (see requirements.txt)

üöÄ Quick Start:
    python main_final.py

Author: Madhukar04012
Version: Final (vFinal)
License: MIT
Repository: https://github.com/Madhukar04012/Number_plate_detection2
"""

import os
import time
import threading
from collections import deque, Counter, defaultdict
from datetime import datetime
from typing import Optional, List, Dict, Set

# Core libraries
import cv2
import numpy as np
from PIL import Image, ImageTk

# GUI framework
import customtkinter as ctk
from tkinter import filedialog, messagebox

# AI/ML
from ultralytics import YOLO

# OCR engines
import pytesseract
import easyocr

# Voice alerts
import pyttsx3

# Embedded charts
import matplotlib
matplotlib.use("TkAgg")
from matplotlib.backends.backend_tkagg import FigureCanvasTkAgg
import matplotlib.pyplot as plt

# ==================== CONFIGURATION ====================

# Model and paths
MODEL_PATH = "models/plate_best.pt"      # Your trained YOLOv8 model
OUTPUT_DIR = "outputs"                   # Saved cropped plates directory
WATCHLIST_FILE = "watchlist.txt"         # Watchlist persistence

# Chart configuration
CHART_WINDOW_SECONDS = 120               # Show last 120 seconds in live chart
CHART_UPDATE_INTERVAL = 1.0              # Update chart every 1 second

# Voice alert throttling (seconds between same plate alerts)
ALERT_THROTTLE_SECONDS = 10.0

# Create output directory
os.makedirs(OUTPUT_DIR, exist_ok=True)

# Uncomment if Tesseract not in PATH (Windows)
# pytesseract.pytesseract.tesseract_cmd = r'C:\Program Files\Tesseract-OCR\tesseract.exe'

# ==================== GLOBAL INITIALIZATION ====================

# Initialize OCR engines (may take a few seconds)
print("üîß Initializing OCR engines...")
try:
    _easyocr_reader = easyocr.Reader(['en'], gpu=True)
    print("‚úÖ EasyOCR initialized with GPU")
except:
    _easyocr_reader = easyocr.Reader(['en'], gpu=False)
    print("‚ö†Ô∏è EasyOCR initialized with CPU (slower)")

# Initialize text-to-speech engine
print("üîß Initializing voice engine...")
_tts_engine = pyttsx3.init()
_tts_engine.setProperty("rate", 160)     # Words per minute
_tts_engine.setProperty("volume", 0.9)   # Volume 0.0 to 1.0
print("‚úÖ Voice engine initialized")

# ==================== UTILITY FUNCTIONS ====================

def speak(text: str):
    """
    Speak text using pyttsx3 (non-blocking)
    
    Args:
        text: Text to speak
    """
    def _speak_thread():
        try:
            _tts_engine.say(text)
            _tts_engine.runAndWait()
        except Exception as e:
            print(f"‚ö†Ô∏è Voice error: {e}")
    
    threading.Thread(target=_speak_thread, daemon=True).start()

def clean_plate_text(text: str) -> str:
    """
    Clean and normalize plate text
    
    Args:
        text: Raw OCR output
        
    Returns:
        Cleaned uppercase alphanumeric text
    """
    text = text.strip()
    text = "".join([c for c in text if c.isalnum()])
    return text.upper()

def ocr_plate(roi_bgr: np.ndarray) -> str:
    """
    Extract text from license plate ROI using dual OCR approach
    
    Args:
        roi_bgr: Cropped plate image in BGR format
        
    Returns:
        Extracted and cleaned plate text
    """
    if roi_bgr is None or roi_bgr.size == 0:
        return ""
    
    try:
        # Convert to grayscale
        gray = cv2.cvtColor(roi_bgr, cv2.COLOR_BGR2GRAY)
        
        # Apply denoising
        denoised = cv2.fastNlMeansDenoising(gray, None, 10, 7, 21)
        
        # Otsu's thresholding
        _, binary = cv2.threshold(denoised, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
        
        text = ""
        
        # Primary: Pytesseract (faster)
        try:
            config = '--psm 7 -c tessedit_char_whitelist=ABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789'
            text = pytesseract.image_to_string(binary, config=config).strip()
        except Exception as e:
            print(f"‚ö†Ô∏è Pytesseract error: {e}")
            text = ""
        
        # Fallback: EasyOCR (more accurate but slower)
        if not text.strip():
            try:
                rgb = cv2.cvtColor(roi_bgr, cv2.COLOR_BGR2RGB)
                results = _easyocr_reader.readtext(rgb)
                text = " ".join([result[1] for result in results if result[2] > 0.3])
            except Exception as e:
                print(f"‚ö†Ô∏è EasyOCR error: {e}")
                text = ""
        
        return clean_plate_text(text)
    
    except Exception as e:
        print(f"‚ö†Ô∏è OCR error: {e}")
        return ""

# ==================== YOLO DETECTOR ====================

class PlateDetectorYOLO:
    """YOLOv8-based license plate detector"""
    
    def __init__(self, model_path: str = MODEL_PATH, conf: float = 0.4, iou: float = 0.45):
        """
        Initialize YOLO detector
        
        Args:
            model_path: Path to trained YOLOv8 weights
            conf: Confidence threshold
            iou: IOU threshold for NMS
        """
        if not os.path.exists(model_path):
            raise FileNotFoundError(f"‚ùå Model not found at: {model_path}")
        
        print(f"üîß Loading YOLO model from {model_path}...")
        self.model = YOLO(model_path)
        self.conf = conf
        self.iou = iou
        print(f"‚úÖ YOLO model loaded successfully")
    
    def set_conf(self, conf: float):
        """Update confidence threshold"""
        self.conf = conf
    
    def detect(self, frame_bgr: np.ndarray) -> List[Dict]:
        """
        Run detection on a BGR frame
        
        Args:
            frame_bgr: Input frame in BGR format
            
        Returns:
            List of detections with keys: x1, y1, x2, y2, conf, roi
        """
        try:
            # Convert BGR to RGB for YOLO
            rgb = cv2.cvtColor(frame_bgr, cv2.COLOR_BGR2RGB)
            
            # Run inference
            results = self.model.predict(rgb, conf=self.conf, iou=self.iou, verbose=False)
            
            detections = []
            
            if not results:
                return detections
            
            result = results[0]
            boxes = getattr(result, "boxes", None)
            
            if boxes is None or len(boxes) == 0:
                return detections
            
            # Process each detection
            for box in boxes:
                try:
                    xyxy = box.xyxy[0].cpu().numpy()
                    conf = float(box.conf[0].cpu().numpy())
                    
                    x1, y1, x2, y2 = [int(v) for v in xyxy]
                    
                    # Clamp coordinates to frame boundaries
                    h, w = frame_bgr.shape[:2]
                    x1 = max(0, min(x1, w - 1))
                    x2 = max(0, min(x2, w - 1))
                    y1 = max(0, min(y1, h - 1))
                    y2 = max(0, min(y2, h - 1))
                    
                    # Validate box dimensions
                    if x2 <= x1 or y2 <= y1:
                        continue
                    
                    # Extract ROI
                    roi = frame_bgr[y1:y2, x1:x2].copy()
                    
                    detections.append({
                        'x1': x1,
                        'y1': y1,
                        'x2': x2,
                        'y2': y2,
                        'conf': conf,
                        'roi': roi
                    })
                
                except Exception as e:
                    print(f"‚ö†Ô∏è Error processing detection: {e}")
                    continue
            
            return detections
        
        except Exception as e:
            print(f"‚ö†Ô∏è Detection error: {e}")
            return []

# ==================== MAIN APPLICATION ====================

class FinalProApp:
    """License Plate Detection System - Final Pro Edition"""
    
    def __init__(self, master: ctk.CTk):
        """
        Initialize the application
        
        Args:
            master: CustomTkinter root window
        """
        self.master = master
        self.master.title("üöó License Plate Detection ‚Äî Final Pro Edition")
        self.master.geometry("1400x800")
        
        # Set theme
        ctk.set_appearance_mode("dark")
        ctk.set_default_color_theme("green")
        
        # Detector (lazy load in background thread to avoid UI blocking)
        self.detector: Optional[PlateDetectorYOLO] = None
        self._detector_ready = False
        self._init_detector_thread = threading.Thread(target=self._load_detector, daemon=True)
        self._init_detector_thread.start()
        
        # Video capture state
        self.cap: Optional[cv2.VideoCapture] = None
        self.video_source: Optional[str] = None  # "camera" or "file"
        self.running = False
        self.video_thread: Optional[threading.Thread] = None
        
        # Detection parameters
        self.conf = 0.4
        self.save_crops = True
        
        # Watchlist management
        self.watchlist: Set[str] = set()
        self.load_watchlist()
        
        # Live chart data (timestamp -> count)
        self.chart_deque = deque(maxlen=CHART_WINDOW_SECONDS)
        self.chart_times = deque(maxlen=CHART_WINDOW_SECONDS)
        self.chart_lock = threading.Lock()
        
        # Recent detections cache (throttle repeated voice alerts)
        self.recent_plate_cache: Dict[str, float] = {}  # plate -> last_alert_time
        
        # Build UI
        self._build_ui()
        
        # Start chart updater thread
        self._chart_updater = threading.Thread(target=self._chart_update_loop, daemon=True)
        self._chart_updater.start()
        
        print("‚úÖ Application initialized successfully")
        print(f"üìä Chart window: {CHART_WINDOW_SECONDS} seconds")
        print(f"üö® Alert throttle: {ALERT_THROTTLE_SECONDS} seconds")
    
    def _load_detector(self):
        """Load YOLO detector in background thread"""
        try:
            self.detector = PlateDetectorYOLO(MODEL_PATH, conf=self.conf)
            self._detector_ready = True
        except Exception as e:
            self.master.after(100, lambda: messagebox.showerror(
                "Model Error",
                f"Failed to load YOLO model:\n\n{e}\n\n"
                f"Please ensure model exists at: {MODEL_PATH}\n"
                f"Train a model using: python train_plate.py"
            ))
            self.master.after(500, self.master.destroy)
    
    # ==================== UI CONSTRUCTION ====================
    
    def _build_ui(self):
        """Build the complete user interface"""
        
        # Left sidebar (controls)
        sidebar = ctk.CTkFrame(self.master, width=320, corner_radius=10)
        sidebar.pack(side="left", fill="y", padx=12, pady=12)
        sidebar.pack_propagate(False)
        
        # Header
        header = ctk.CTkLabel(
            sidebar,
            text="üöó Controls",
            font=("Arial", 22, "bold"),
            text_color="#00FF41"
        )
        header.pack(pady=(12, 10))
        
        # Video source controls
        self._add_section_label(sidebar, "üìπ Video Source")
        
        ctk.CTkButton(
            sidebar,
            text="‚ñ∂Ô∏è Start Webcam",
            command=self.start_camera,
            height=40,
            font=("Arial", 13, "bold"),
            fg_color="#00AA00",
            hover_color="#00DD00"
        ).pack(pady=5, padx=15, fill="x")
        
        ctk.CTkButton(
            sidebar,
            text="üìÅ Open Video File",
            command=self.open_video_file,
            height=40,
            font=("Arial", 13, "bold"),
            fg_color="#0066CC",
            hover_color="#0088FF"
        ).pack(pady=5, padx=15, fill="x")
        
        ctk.CTkButton(
            sidebar,
            text="‚èπÔ∏è Stop",
            command=self.stop_video,
            height=40,
            font=("Arial", 13, "bold"),
            fg_color="#AA0000",
            hover_color="#DD0000"
        ).pack(pady=5, padx=15, fill="x")
        
        # File operations
        self._add_section_label(sidebar, "üìÅ File Operations")
        
        ctk.CTkButton(
            sidebar,
            text="üì∑ Upload Image",
            command=self.upload_image,
            height=35
        ).pack(pady=4, padx=15, fill="x")
        
        ctk.CTkButton(
            sidebar,
            text="üìÇ Batch Folder",
            command=self.batch_folder,
            height=35
        ).pack(pady=4, padx=15, fill="x")
        
        # Settings
        self._add_section_label(sidebar, "‚öôÔ∏è Settings")
        
        # Confidence slider
        conf_label = ctk.CTkLabel(
            sidebar,
            text=f"Confidence: {self.conf:.2f}",
            font=("Arial", 12)
        )
        conf_label.pack(pady=(8, 4))
        
        def update_conf_label(val):
            self.conf = float(val)
            conf_label.configure(text=f"Confidence: {self.conf:.2f}")
            if self.detector:
                self.detector.set_conf(self.conf)
        
        self.conf_slider = ctk.CTkSlider(
            sidebar,
            from_=0.05,
            to=0.99,
            number_of_steps=38,
            command=update_conf_label,
            height=20
        )
        self.conf_slider.set(self.conf)
        self.conf_slider.pack(pady=5, padx=15, fill="x")
        
        # Save crops toggle
        self.save_switch = ctk.CTkSwitch(
            sidebar,
            text="üíæ Save Cropped Plates",
            command=self.on_toggle_save,
            font=("Arial", 12)
        )
        self.save_switch.select()
        self.save_switch.pack(pady=10, padx=15)
        
        # Watchlist section
        self._add_section_label(sidebar, "üö® Watchlist (Voice Alerts)")
        
        self.watch_entry = ctk.CTkEntry(
            sidebar,
            placeholder_text="Enter plate number...",
            height=35,
            font=("Arial", 12)
        )
        self.watch_entry.pack(pady=5, padx=15, fill="x")
        
        ctk.CTkButton(
            sidebar,
            text="‚ûï Add to Watchlist",
            command=self.add_watch,
            height=32,
            fg_color="#FF8800",
            hover_color="#FFAA00"
        ).pack(pady=3, padx=15, fill="x")
        
        ctk.CTkButton(
            sidebar,
            text="üóëÔ∏è Clear Watchlist",
            command=self.clear_watch,
            height=32,
            fg_color="#666666",
            hover_color="#888888"
        ).pack(pady=3, padx=15, fill="x")
        
        # Statistics section
        self._add_section_label(sidebar, "üìä Live Statistics")
        
        self.total_detected_var = ctk.StringVar(value="Total detections: 0")
        stats_label = ctk.CTkLabel(
            sidebar,
            textvariable=self.total_detected_var,
            font=("Arial", 14, "bold"),
            text_color="#00FF41"
        )
        stats_label.pack(pady=8)
        
        ctk.CTkButton(
            sidebar,
            text="üìà Show Full Stats",
            command=self._show_full_stats,
            height=35,
            fg_color="#0088DD",
            hover_color="#00AAFF"
        ).pack(pady=5, padx=15, fill="x")
        
        # Status at bottom of sidebar
        self.status_var = ctk.StringVar(value="‚è≥ Loading model...")
        status_label = ctk.CTkLabel(
            sidebar,
            textvariable=self.status_var,
            font=("Arial", 10),
            text_color="#888888",
            wraplength=280
        )
        status_label.pack(side="bottom", pady=15)
        
        # Right main area (video display + preview + chart)
        right_frame = ctk.CTkFrame(self.master, corner_radius=10)
        right_frame.pack(side="right", fill="both", expand=True, padx=12, pady=12)
        
        # Title
        title = ctk.CTkLabel(
            right_frame,
            text="üé• Detection Feed",
            font=("Arial", 20, "bold")
        )
        title.pack(pady=10)
        
        # Video display
        self.video_label = ctk.CTkLabel(
            right_frame,
            text="üì∏ No feed active\n\nStart webcam, open video file, or upload image",
            font=("Arial", 14),
            text_color="#666666"
        )
        self.video_label.pack(pady=15)
        
        # Bottom area: preview + chart
        bottom_frame = ctk.CTkFrame(right_frame, fg_color="transparent")
        bottom_frame.pack(fill="x", pady=10, padx=10)
        
        # Left: Preview
        preview_container = ctk.CTkFrame(bottom_frame, corner_radius=10)
        preview_container.grid(row=0, column=0, padx=10, pady=5, sticky="nsew")
        
        ctk.CTkLabel(
            preview_container,
            text="üîç Last Detected Plate",
            font=("Arial", 14, "bold")
        ).pack(pady=5)
        
        self.preview_image_label = ctk.CTkLabel(
            preview_container,
            text="Waiting for detection...",
            font=("Arial", 11),
            text_color="#888888"
        )
        self.preview_image_label.pack(pady=10)
        
        # Right: Embedded chart
        chart_container = ctk.CTkFrame(bottom_frame, corner_radius=10)
        chart_container.grid(row=0, column=1, padx=10, pady=5, sticky="nsew")
        
        bottom_frame.grid_columnconfigure(0, weight=1)
        bottom_frame.grid_columnconfigure(1, weight=2)
        
        # Create Matplotlib figure
        self.fig, self.ax = plt.subplots(figsize=(7, 3))
        self.fig.patch.set_facecolor('#2a2a2a')
        self.ax.set_facecolor('#1a1a1a')
        self.ax.set_title(
            f"Detections per second (last {CHART_WINDOW_SECONDS}s)",
            color='white',
            fontsize=12,
            fontweight='bold'
        )
        self.ax.set_xlabel("seconds ago", color='white')
        self.ax.set_ylabel("count", color='white')
        self.ax.tick_params(colors='white')
        self.ax.spines['bottom'].set_color('white')
        self.ax.spines['left'].set_color('white')
        self.ax.spines['top'].set_visible(False)
        self.ax.spines['right'].set_visible(False)
        
        # Embed chart in Tkinter
        self.canvas = FigureCanvasTkAgg(self.fig, master=chart_container)
        self.canvas.get_tk_widget().pack(fill="both", expand=True, padx=5, pady=5)
        
        # Update status when model loads
        self.master.after(100, self._check_model_status)
    
    def _check_model_status(self):
        """Check if model is loaded and update status"""
        if self._detector_ready:
            self.status_var.set("‚úÖ Ready | Model: YOLOv8 | OCR: Active | Voice: Enabled")
        else:
            self.master.after(100, self._check_model_status)
    
    def _add_section_label(self, parent, text: str):
        """Helper to add section headers"""
        label = ctk.CTkLabel(
            parent,
            text=text,
            font=("Arial", 13, "bold"),
            text_color="#AAAAAA"
        )
        label.pack(pady=(15, 5))
    
    # ==================== WATCHLIST MANAGEMENT ====================
    
    def load_watchlist(self):
        """Load watchlist from file"""
        try:
            if os.path.exists(WATCHLIST_FILE):
                with open(WATCHLIST_FILE, "r") as f:
                    self.watchlist = set([
                        line.strip().upper()
                        for line in f
                        if line.strip()
                    ])
                print(f"‚úÖ Loaded {len(self.watchlist)} plates from watchlist")
            else:
                self.watchlist = set()
        except Exception as e:
            print(f"‚ö†Ô∏è Error loading watchlist: {e}")
            self.watchlist = set()
    
    def save_watchlist(self):
        """Save watchlist to file"""
        try:
            with open(WATCHLIST_FILE, "w") as f:
                for plate in sorted(self.watchlist):
                    f.write(plate + "\n")
        except Exception as e:
            print(f"‚ö†Ô∏è Error saving watchlist: {e}")
    
    def add_watch(self):
        """Add plate to watchlist"""
        plate = self.watch_entry.get().strip().upper()
        
        if not plate:
            messagebox.showinfo("Input Required", "Please enter a plate number")
            return
        
        if plate in self.watchlist:
            messagebox.showinfo("Already Added", f"{plate} is already in the watchlist")
            return
        
        self.watchlist.add(plate)
        self.save_watchlist()
        self.watch_entry.delete(0, 'end')
        
        messagebox.showinfo(
            "Watchlist Updated",
            f"‚úÖ {plate} added to watchlist\n\n"
            f"Voice alert will trigger when detected"
        )
        
        speak(f"Watchlist updated. Added {plate}")
    
    def clear_watch(self):
        """Clear watchlist"""
        if not self.watchlist:
            messagebox.showinfo("Empty", "Watchlist is already empty")
            return
        
        response = messagebox.askyesno(
            "Clear Watchlist",
            f"Remove all {len(self.watchlist)} plates from watchlist?"
        )
        
        if response:
            self.watchlist.clear()
            self.save_watchlist()
            messagebox.showinfo("Cleared", "Watchlist cleared")
            speak("Watchlist cleared")
    
    # ==================== CONTROLS ====================
    
    def on_toggle_save(self):
        """Toggle save crops setting"""
        self.save_crops = not self.save_crops
        status = "enabled" if self.save_crops else "disabled"
        print(f"üíæ Save cropped plates: {status}")
    
    # ==================== VIDEO/CAMERA HANDLING ====================
    
    def start_camera(self):
        """Start webcam capture"""
        if self.running:
            messagebox.showwarning("Already Running", "Stop current stream first")
            return
        
        if not self._detector_ready:
            messagebox.showinfo(
                "Please Wait",
                "Model is still loading...\nPlease wait a few seconds and try again"
            )
            return
        
        self.cap = cv2.VideoCapture(0)
        
        if not self.cap.isOpened():
            messagebox.showerror("Webcam Error", "Unable to open webcam")
            return
        
        self.running = True
        self.video_source = "camera"
        self.status_var.set("üî¥ LIVE | Webcam Active")
        
        self.video_thread = threading.Thread(target=self._video_loop, daemon=True)
        self.video_thread.start()
        
        speak("Webcam started")
    
    def open_video_file(self):
        """Open and process video file"""
        if self.running:
            messagebox.showinfo("Stop First", "Stop current stream before opening file")
            return
        
        if not self._detector_ready:
            messagebox.showinfo(
                "Please Wait",
                "Model is still loading...\nPlease wait and try again"
            )
            return
        
        filepath = filedialog.askopenfilename(
            title="Select Video File",
            filetypes=[
                ("Video Files", "*.mp4 *.avi *.mov *.mkv *.flv"),
                ("All Files", "*.*")
            ]
        )
        
        if not filepath:
            return
        
        cap = cv2.VideoCapture(filepath)
        
        if not cap.isOpened():
            messagebox.showerror("Video Error", "Unable to open selected video file")
            return
        
        self.cap = cap
        self.running = True
        self.video_source = "file"
        self.status_var.set(f"üìπ Playing: {os.path.basename(filepath)}")
        
        self.video_thread = threading.Thread(target=self._video_loop, daemon=True)
        self.video_thread.start()
        
        speak("Video file loaded")
    
    def stop_video(self):
        """Stop video/camera capture"""
        if not self.running:
            messagebox.showinfo("Not Running", "No video source is active")
            return
        
        self.running = False
        time.sleep(0.05)
        
        if self.cap:
            try:
                self.cap.release()
            except Exception:
                pass
        
        self.cap = None
        self.video_source = None
        
        # Clear displays
        self.video_label.configure(
            image=None,
            text="üì∏ Feed stopped\n\nStart webcam or open video file"
        )
        self.preview_image_label.configure(image=None, text="Waiting for detection...")
        
        self.status_var.set("‚úÖ Ready | Stream stopped")
        speak("Stream stopped")
    
    def upload_image(self):
        """Upload and process single image"""
        filepath = filedialog.askopenfilename(
            title="Select Image",
            filetypes=[
                ("Image Files", "*.jpg *.jpeg *.png *.bmp"),
                ("All Files", "*.*")
            ]
        )
        
        if not filepath:
            return
        
        if not self._detector_ready:
            messagebox.showinfo("Please Wait", "Model is still loading...")
            return
        
        frame = cv2.imread(filepath)
        
        if frame is None:
            messagebox.showerror("Error", "Could not read image file")
            return
        
        self.status_var.set(f"üì∑ Processing: {os.path.basename(filepath)}")
        self._process_frame_and_display(frame, save_if=True)
        self.status_var.set("‚úÖ Ready | Image processed")
    
    def batch_folder(self):
        """Process all images in a folder"""
        folder = filedialog.askdirectory(title="Select Folder")
        
        if not folder:
            return
        
        if not self._detector_ready:
            messagebox.showinfo("Please Wait", "Model is still loading...")
            return
        
        # Get image files
        image_extensions = ('.jpg', '.jpeg', '.png', '.bmp')
        images = [
            f for f in os.listdir(folder)
            if f.lower().endswith(image_extensions)
        ]
        
        if not images:
            messagebox.showinfo("No Images", "No image files found in folder")
            return
        
        response = messagebox.askyesno(
            "Batch Processing",
            f"Found {len(images)} images.\n\nProcess all?"
        )
        
        if not response:
            return
        
        processed = 0
        
        for filename in images:
            filepath = os.path.join(folder, filename)
            frame = cv2.imread(filepath)
            
            if frame is not None:
                self.status_var.set(f"üìÇ Processing {processed + 1}/{len(images)}")
                self._process_frame_and_display(frame, save_if=self.save_crops)
                self.master.update()
                time.sleep(0.05)
                processed += 1
        
        messagebox.showinfo(
            "Batch Complete",
            f"‚úÖ Processed {processed} of {len(images)} images\n\n"
            f"Cropped plates saved to: {OUTPUT_DIR}"
        )
        
        self.status_var.set("‚úÖ Ready | Batch complete")
        speak(f"Batch processing complete. {processed} images processed")
    
    def _video_loop(self):
        """Main video capture loop (runs in separate thread)"""
        fps_sleep = 0.02  # ~50 fps max
        
        while self.running and self.cap and self.cap.isOpened():
            ret, frame = self.cap.read()
            
            if not ret:
                break
            
            # Process frame
            self._process_frame_and_display(frame, save_if=False, live=True)
            
            time.sleep(fps_sleep)
            
            # Check if video file ended
            if self.video_source == "file":
                current_frame = int(self.cap.get(cv2.CAP_PROP_POS_FRAMES))
                total_frames = int(self.cap.get(cv2.CAP_PROP_FRAME_COUNT))
                
                if current_frame >= total_frames:
                    break
        
        # Clean up
        self.running = False
        
        if self.cap:
            try:
                self.cap.release()
            except Exception:
                pass
        
        self.cap = None
        self.video_source = None
        
        # Update UI
        self.master.after(0, lambda: self.status_var.set("‚úÖ Ready | Video ended"))
    
    # ==================== FRAME PROCESSING ====================
    
    def _process_frame_and_display(
        self,
        frame_bgr: np.ndarray,
        save_if: bool = False,
        live: bool = False
    ):
        """
        Process frame, run detection, OCR, and update UI
        
        Args:
            frame_bgr: Input frame in BGR format
            save_if: Whether to save cropped plates
            live: Whether in live video mode
        """
        if self.detector is None:
            return
        
        # Run detection
        detections = self.detector.detect(frame_bgr)
        
        # Draw on frame
        frame_draw = frame_bgr.copy()
        chosen_roi = None
        detected_texts = []
        
        for det in detections:
            x1, y1, x2, y2 = det['x1'], det['y1'], det['x2'], det['y2']
            roi = det['roi']
            conf = det.get('conf', 0.0)
            
            # Run OCR
            text = ocr_plate(roi)
            
            if text:
                detected_texts.append(text)
            
            # Draw bounding box
            cv2.rectangle(frame_draw, (x1, y1), (x2, y2), (255, 0, 255), 2)
            
            # Draw label with background
            label = f"{text if text else 'Plate'} {conf:.2f}"
            label_size, _ = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 2)
            
            # Label background
            cv2.rectangle(
                frame_draw,
                (x1, y1 - 25),
                (x1 + label_size[0] + 10, y1),
                (255, 0, 255),
                -1
            )
            
            # Label text
            cv2.putText(
                frame_draw,
                label,
                (x1 + 5, y1 - 5),
                cv2.FONT_HERSHEY_SIMPLEX,
                0.6,
                (255, 255, 255),
                2
            )
            
            chosen_roi = roi
            
            # Save crop if enabled
            if self.save_crops and save_if and text:
                timestamp = datetime.now().strftime('%Y%m%d_%H%M%S_%f')
                filename = f"{text}_{timestamp}.jpg"
                cv2.imwrite(os.path.join(OUTPUT_DIR, filename), roi)
            
            # Watchlist alert with voice (throttled)
            if text and text in self.watchlist:
                last_alert = self.recent_plate_cache.get(text, 0.0)
                now = time.time()
                
                if now - last_alert > ALERT_THROTTLE_SECONDS:
                    self.recent_plate_cache[text] = now
                    
                    # Voice alert
                    speak(f"Watchlist alert! Plate {text} detected!")
                    
                    # Visual alert (non-blocking)
                    self.master.after(10, lambda t=text: messagebox.showwarning(
                        "üö® WATCHLIST ALERT üö®",
                        f"Watchlisted plate detected!\n\n"
                        f"Plate: {t}\n"
                        f"Time: {datetime.now().strftime('%H:%M:%S')}\n\n"
                        f"‚ö†Ô∏è IMMEDIATE ATTENTION REQUIRED"
                    ))
        
        # Update chart data
        with self.chart_lock:
            now = time.time()
            count = len(detected_texts)
            self.chart_times.append(now)
            self.chart_deque.append(count)
            
            # Update total counter
            total = sum(self.chart_deque)
            self.total_detected_var.set(f"Total detections: {total}")
        
        # Update video display
        try:
            rgb = cv2.cvtColor(frame_draw, cv2.COLOR_BGR2RGB)
            height, width = rgb.shape[:2]
            scale = min(1000 / width, 600 / height)
            new_size = (int(width * scale), int(height * scale))
            
            resized = cv2.resize(rgb, new_size)
            img = ImageTk.PhotoImage(Image.fromarray(resized))
            
            self.video_label.configure(image=img, text="")
            self.video_label.image = img
        except Exception as e:
            print(f"‚ö†Ô∏è Display error: {e}")
        
        # Update preview
        if chosen_roi is not None:
            try:
                p_rgb = cv2.cvtColor(chosen_roi, cv2.COLOR_BGR2RGB)
                p_height, p_width = p_rgb.shape[:2]
                p_scale = min(280 / p_width, 120 / p_height)
                p_size = (int(p_width * p_scale), int(p_height * p_scale))
                
                p_resized = cv2.resize(p_rgb, p_size)
                p_img = ImageTk.PhotoImage(Image.fromarray(p_resized))
                
                self.preview_image_label.configure(image=p_img, text="")
                self.preview_image_label.image = p_img
            except Exception as e:
                print(f"‚ö†Ô∏è Preview error: {e}")
    
    # ==================== CHART UPDATER ====================
    
    def _chart_update_loop(self):
        """Background thread to update chart periodically"""
        while True:
            time.sleep(CHART_UPDATE_INTERVAL)
            
            with self.chart_lock:
                if len(self.chart_deque) == 0:
                    xs = []
                    ys = []
                else:
                    now = time.time()
                    times = list(self.chart_times)
                    counts = list(self.chart_deque)
                    
                    # Calculate seconds ago (negative)
                    xs = [int(now - t) * -1 for t in times]
                    ys = counts
                
                # Update chart in main thread
                try:
                    self.master.after(1, lambda x=xs, y=ys: self._update_chart(x, y))
                except Exception:
                    pass
    
    def _update_chart(self, xs: List[int], ys: List[int]):
        """Update the embedded matplotlib chart"""
        try:
            if len(xs) == 0:
                self.ax.clear()
                self.ax.set_facecolor('#1a1a1a')
                self.ax.set_title(
                    f"Detections per second (last {CHART_WINDOW_SECONDS}s)",
                    color='white',
                    fontsize=12,
                    fontweight='bold'
                )
                self.ax.set_xlabel("seconds ago", color='white')
                self.ax.set_ylabel("count", color='white')
                self.ax.tick_params(colors='white')
                self.ax.spines['bottom'].set_color('white')
                self.ax.spines['left'].set_color('white')
                self.ax.spines['top'].set_visible(False)
                self.ax.spines['right'].set_visible(False)
                self.canvas.draw()
                return
            
            # Aggregate by second
            xs_pos = [abs(int(v)) for v in xs]
            agg = defaultdict(int)
            
            for s, c in zip(xs_pos, ys):
                if s <= CHART_WINDOW_SECONDS:
                    agg[s] += c
            
            x_sorted = sorted(agg.keys())
            y_vals = [agg[k] for k in x_sorted]
            
            # Update chart
            self.ax.clear()
            self.ax.set_facecolor('#1a1a1a')
            self.ax.bar([-k for k in x_sorted], y_vals, color='#00FF41', width=1.0)
            self.ax.set_title(
                f"Detections per second (last {CHART_WINDOW_SECONDS}s)",
                color='white',
                fontsize=12,
                fontweight='bold'
            )
            self.ax.set_xlabel("seconds ago", color='white')
            self.ax.set_ylabel("count", color='white')
            self.ax.tick_params(colors='white')
            self.ax.spines['bottom'].set_color('white')
            self.ax.spines['left'].set_color('white')
            self.ax.spines['top'].set_visible(False)
            self.ax.spines['right'].set_visible(False)
            
            self.canvas.draw()
        
        except Exception as e:
            print(f"‚ö†Ô∏è Chart update error: {e}")
    
    # ==================== STATISTICS ====================
    
    def _show_full_stats(self):
        """Show detailed statistics popup"""
        # Count recent watchlist hits
        counts = Counter()
        now = time.time()
        
        for plate, last_time in self.recent_plate_cache.items():
            # Last hour only
            if now - last_time <= 3600:
                counts[plate] += 1
        
        # Build message
        total_in_window = sum(self.chart_deque)
        unique_recent = len(set([p for p in self.recent_plate_cache.keys()]))
        
        text = f"üìä Session Statistics\n\n"
        text += f"Total detections (last {CHART_WINDOW_SECONDS}s): {total_in_window}\n"
        text += f"Unique plates detected: {unique_recent}\n"
        text += f"Watchlist size: {len(self.watchlist)}\n\n"
        text += f"Recent watchlist alerts (last hour):\n\n"
        
        if counts:
            for plate, count in counts.most_common():
                text += f"  {plate}: {count} alert(s)\n"
        else:
            text += "  No recent alerts\n"
        
        text += f"\nüíæ Cropped plates: {OUTPUT_DIR}/"
        
        messagebox.showinfo("Full Statistics", text)

# ==================== MAIN ENTRY POINT ====================

def main():
    """Main entry point for the application"""
    print("=" * 70)
    print("üöó License Plate Detection System ‚Äî Final Pro Edition")
    print("=" * 70)
    print()
    print("‚ú® Features:")
    print("  ‚Ä¢ YOLOv8 AI detection")
    print("  ‚Ä¢ Dual OCR (Pytesseract + EasyOCR)")
    print("  ‚Ä¢ Webcam + Video file support")
    print("  ‚Ä¢ Voice alerts (pyttsx3)")
    print("  ‚Ä¢ Live embedded charts")
    print("  ‚Ä¢ Database-free architecture")
    print()
    
    # Check model exists
    if not os.path.exists(MODEL_PATH):
        print(f"‚ùå Model not found at: {MODEL_PATH}")
        print()
        print("Please train a model first:")
        print("  python train_plate.py")
        print()
        print("Or download a pre-trained model:")
        print("  python download_pretrained_model.py")
        print()
        return
    
    # Create and run application
    root = ctk.CTk()
    app = FinalProApp(root)
    
    print("‚úÖ Application started successfully")
    print("üí° Use the sidebar controls to begin detection")
    print()
    print("=" * 70)
    print()
    
    root.mainloop()
    
    print()
    print("=" * 70)
    print("üëã Application closed")
    print("=" * 70)

if __name__ == "__main__":
    main()
